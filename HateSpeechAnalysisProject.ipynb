{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62ee1065",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install nltk\n",
    "#!pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "deed9754",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\aminm\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\aminm\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import warnings\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "806799b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>count</th>\n",
       "      <th>hate_speech</th>\n",
       "      <th>offensive_language</th>\n",
       "      <th>neither</th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>\" momma said no pussy cats inside my doghouse \"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>63</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>\"@Addicted2Guys: -SimplyAddictedToGuys http://...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>66</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>\"@AllAboutManFeet: http://t.co/3gzUpfuMev\" woo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>67</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>\"@Allyhaaaaa: Lemmie eat a Oreo &amp;amp; do these...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0  count  hate_speech  offensive_language  neither  class   \n",
       "0            0      3            0                   0        3      2  \\\n",
       "40          40      3            0                   1        2      2   \n",
       "63          63      3            0                   0        3      2   \n",
       "66          66      3            0                   1        2      2   \n",
       "67          67      3            0                   1        2      2   \n",
       "\n",
       "                                                tweet  \n",
       "0   !!! RT @mayasolovely: As a woman you shouldn't...  \n",
       "40    \" momma said no pussy cats inside my doghouse \"  \n",
       "63  \"@Addicted2Guys: -SimplyAddictedToGuys http://...  \n",
       "66  \"@AllAboutManFeet: http://t.co/3gzUpfuMev\" woo...  \n",
       "67  \"@Allyhaaaaa: Lemmie eat a Oreo &amp; do these...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read the file\n",
    "df = pd.read_csv('labeled_data.csv')\n",
    "df = df[df['class'] != 1]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b0aac2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the 0 into hateful and 1, 2 into non-hatefull\n",
    "df['target'] = df['class'].apply(lambda x: 'hateful' if x == 0 else \"non-hateful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d51541be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
       "      <td>non-hateful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>\" momma said no pussy cats inside my doghouse \"</td>\n",
       "      <td>non-hateful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>\"@Addicted2Guys: -SimplyAddictedToGuys http://...</td>\n",
       "      <td>non-hateful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>\"@AllAboutManFeet: http://t.co/3gzUpfuMev\" woo...</td>\n",
       "      <td>non-hateful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>\"@Allyhaaaaa: Lemmie eat a Oreo &amp;amp; do these...</td>\n",
       "      <td>non-hateful</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                tweet       target\n",
       "0   !!! RT @mayasolovely: As a woman you shouldn't...  non-hateful\n",
       "40    \" momma said no pussy cats inside my doghouse \"  non-hateful\n",
       "63  \"@Addicted2Guys: -SimplyAddictedToGuys http://...  non-hateful\n",
       "66  \"@AllAboutManFeet: http://t.co/3gzUpfuMev\" woo...  non-hateful\n",
       "67  \"@Allyhaaaaa: Lemmie eat a Oreo &amp; do these...  non-hateful"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[['tweet','target']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "14835925",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "non-hateful    4163\n",
       "hateful        1430\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"target\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e72ce51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tweet'] = df['tweet'].fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d9bb728c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "#import seaborn as sns\n",
    "\n",
    "# Assuming you have a DataFrame 'df' with columns 'target'\n",
    "x = list(df['target'].unique())\n",
    "y = df['target'].value_counts()\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "ax = sns.barplot(x=x, y=y, alpha=0.8)\n",
    "#plt.title(\"Your Title Here\")\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"total tweets\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1c170e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change the boolean value if you don't check the stop words\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "stop_word_flag = True\n",
    "\n",
    "def clean_data(text_list,label_list):\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    stemmer = PorterStemmer()\n",
    "    lemmater = WordNetLemmatizer()\n",
    "    stop_word = set(stopwords.words('english'))\n",
    "    pre_text_list = []\n",
    "    pre_label_list = []\n",
    "    for i in range(len(text_list)):\n",
    "        text_list[i] = re.sub('RT','',text_list[i])\n",
    "        #normalize the case\n",
    "        text_list[i] = text_list[i].lower()\n",
    "        #remove the endline\n",
    "        text_list[i] = re.sub('\\n','',text_list[i])\n",
    "        #Remove the tag, mentions and links\n",
    "        text_list[i] = re.sub(r\"(?:\\@|http?\\://|https?\\://|www|#)\\S+\", \"\", text_list[i])\n",
    "        #remove the punctiontions and numbers and remove the stop words\n",
    "        text_list[i] = ' '.join([stemmer.stem(lemmater.lemmatize(word)) for word in tokenizer.tokenize(text_list[i]) if word not in stop_word and stop_word_flag])    \n",
    "        if text_list[i]:\n",
    "            pre_text_list.append(text_list[i])\n",
    "            pre_label_list.append(label_list[i])\n",
    "    return pre_text_list, pre_label_list\n",
    "tweets_list, y_labels = clean_data(df['tweet'].tolist(),df['target'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e971c293",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ec2ab17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# TFIDF Vectoriztion that convert the word into numerical values/features\n",
    "vect_tfidf = TfidfVectorizer()\n",
    "#Fit and transform the training features\n",
    "X_matrix = vect_tfidf.fit_transform(tweets_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "37267ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "smt = SMOTE()\n",
    "#used SMOTE for balanced the dataset using oversampling\n",
    "X_tfidf_smote, y_tfidf_smote = smt.fit_resample(X_matrix,y_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eb2c9b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# Count Vectoriztion that convert the word into numerical values/features\n",
    "vect_count = CountVectorizer()\n",
    "#Fit and transform the training features\n",
    "X_matrix = vect_count.fit_transform(tweets_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "833e282d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "smt = SMOTE()\n",
    "#used SMOTE for balanced the dataset using oversampling\n",
    "X_count_smote, y_count_smote = smt.fit_resample(X_matrix,y_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7399300b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "testset_file_names = [file for file in glob.glob('testset/*')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c3f2719d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['testset\\\\hatecheck_test_data_group_black people.csv',\n",
       " 'testset\\\\hatecheck_test_data_group_disabled people.csv',\n",
       " 'testset\\\\hatecheck_test_data_group_gay people.csv',\n",
       " 'testset\\\\hatecheck_test_data_group_immigrants.csv',\n",
       " 'testset\\\\hatecheck_test_data_group_Muslims.csv',\n",
       " 'testset\\\\hatecheck_test_data_group_trans people.csv',\n",
       " 'testset\\\\hatecheck_test_data_group_women.csv']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset_file_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a9e639c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.60077181\n",
      "Iteration 2, loss = 0.16518058\n",
      "Iteration 3, loss = 0.03801563\n",
      "Iteration 4, loss = 0.01571873\n",
      "Iteration 5, loss = 0.00741252\n",
      "Iteration 6, loss = 0.00476776\n",
      "Iteration 7, loss = 0.00357124\n",
      "Iteration 8, loss = 0.00352266\n",
      "Iteration 9, loss = 0.00260403\n",
      "Iteration 10, loss = 0.00277744\n",
      "Iteration 11, loss = 0.00201640\n",
      "Iteration 12, loss = 0.00242084\n",
      "Iteration 13, loss = 0.00232583\n",
      "Iteration 14, loss = 0.00224622\n",
      "Iteration 15, loss = 0.00247585\n",
      "Iteration 16, loss = 0.00180891\n",
      "Iteration 17, loss = 0.00253032\n",
      "Iteration 18, loss = 0.00233979\n",
      "Iteration 19, loss = 0.00259795\n",
      "Iteration 20, loss = 0.00206217\n",
      "Iteration 21, loss = 0.00238693\n",
      "Iteration 22, loss = 0.00189923\n",
      "Iteration 23, loss = 0.00183035\n",
      "Iteration 24, loss = 0.00190932\n",
      "Iteration 25, loss = 0.00191957\n",
      "Iteration 26, loss = 0.00173225\n",
      "Iteration 27, loss = 0.00167078\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "clf_mlp = MLPClassifier(hidden_layer_sizes=(128,64,32,), activation='relu' ,random_state=1, max_iter=300,verbose=True).fit(X_tfidf_smote, y_tfidf_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "25c7b546",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Cross Validation\n",
    "# k_fold = 8\n",
    "# cross_val_score(estimator = clf_mlp, X = X_count_smote, y = y_count_smote, cv = k_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9467e797",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6b273988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TestSet(hatecheck_test_data_group_black people) LogisticRegression using TfidfVectorizer\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     hateful       0.75      0.64      0.69       357\n",
      " non-hateful       0.28      0.40      0.33       125\n",
      "\n",
      "    accuracy                           0.58       482\n",
      "   macro avg       0.52      0.52      0.51       482\n",
      "weighted avg       0.63      0.58      0.60       482\n",
      "\n",
      "Confusion Matrix\n",
      "[[230 127]\n",
      " [ 75  50]]\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "TestSet(hatecheck_test_data_group_disabled people) LogisticRegression using TfidfVectorizer\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     hateful       0.81      0.42      0.56       373\n",
      " non-hateful       0.25      0.66      0.37       111\n",
      "\n",
      "    accuracy                           0.48       484\n",
      "   macro avg       0.53      0.54      0.46       484\n",
      "weighted avg       0.68      0.48      0.51       484\n",
      "\n",
      "Confusion Matrix\n",
      "[[158 215]\n",
      " [ 38  73]]\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "TestSet(hatecheck_test_data_group_gay people) LogisticRegression using TfidfVectorizer\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     hateful       0.68      0.89      0.77       373\n",
      " non-hateful       0.33      0.11      0.17       178\n",
      "\n",
      "    accuracy                           0.64       551\n",
      "   macro avg       0.50      0.50      0.47       551\n",
      "weighted avg       0.56      0.64      0.57       551\n",
      "\n",
      "Confusion Matrix\n",
      "[[332  41]\n",
      " [158  20]]\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "TestSet(hatecheck_test_data_group_immigrants) LogisticRegression using TfidfVectorizer\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     hateful       0.77      0.21      0.33       357\n",
      " non-hateful       0.23      0.79      0.36       106\n",
      "\n",
      "    accuracy                           0.34       463\n",
      "   macro avg       0.50      0.50      0.34       463\n",
      "weighted avg       0.65      0.34      0.34       463\n",
      "\n",
      "Confusion Matrix\n",
      "[[ 75 282]\n",
      " [ 22  84]]\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "TestSet(hatecheck_test_data_group_Muslims) LogisticRegression using TfidfVectorizer\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     hateful       0.81      0.71      0.75       373\n",
      " non-hateful       0.30      0.42      0.35       111\n",
      "\n",
      "    accuracy                           0.64       484\n",
      "   macro avg       0.55      0.57      0.55       484\n",
      "weighted avg       0.69      0.64      0.66       484\n",
      "\n",
      "Confusion Matrix\n",
      "[[265 108]\n",
      " [ 64  47]]\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "TestSet(hatecheck_test_data_group_trans people) LogisticRegression using TfidfVectorizer\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     hateful       0.81      0.55      0.66       357\n",
      " non-hateful       0.28      0.58      0.37       106\n",
      "\n",
      "    accuracy                           0.56       463\n",
      "   macro avg       0.55      0.56      0.52       463\n",
      "weighted avg       0.69      0.56      0.59       463\n",
      "\n",
      "Confusion Matrix\n",
      "[[197 160]\n",
      " [ 45  61]]\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "TestSet(hatecheck_test_data_group_women) LogisticRegression using TfidfVectorizer\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     hateful       0.76      0.48      0.59       373\n",
      " non-hateful       0.29      0.59      0.39       136\n",
      "\n",
      "    accuracy                           0.51       509\n",
      "   macro avg       0.53      0.53      0.49       509\n",
      "weighted avg       0.64      0.51      0.54       509\n",
      "\n",
      "Confusion Matrix\n",
      "[[179 194]\n",
      " [ 56  80]]\n",
      "--------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for file_name in testset_file_names:\n",
    "    #read the test file \n",
    "    df_test = pd.read_csv(file_name)\n",
    "    #clean the text of test set\n",
    "    X_test, y_test = clean_data(df_test[\"text\"].tolist(),df_test[\"label\"].tolist())\n",
    "    #transform the matrix\n",
    "    X_test_Matrix = vect_tfidf.transform(X_test)\n",
    "    #predict the matrix\n",
    "    y_pred = clf_mlp.predict(X_test_Matrix)\n",
    "    title = 'TestSet({}) LogisticRegression using TfidfVectorizer'.format(file_name[8:-4])\n",
    "    print(title)\n",
    "    cls_report = classification_report(y_test, y_pred)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    print(\"Classification Report\")\n",
    "    print(cls_report)\n",
    "    print(\"Confusion Matrix\")\n",
    "    print(conf_matrix)\n",
    "    print(\"-\"*110)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "14c75170",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<509x8064 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 1824 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d5db8904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.54668627\n",
      "Iteration 2, loss = 0.15678569\n",
      "Iteration 3, loss = 0.06248380\n",
      "Iteration 4, loss = 0.03287327\n",
      "Iteration 5, loss = 0.02249258\n",
      "Iteration 6, loss = 0.01624618\n",
      "Iteration 7, loss = 0.01377344\n",
      "Iteration 8, loss = 0.01223907\n",
      "Iteration 9, loss = 0.01135732\n",
      "Iteration 10, loss = 0.01063058\n",
      "Iteration 11, loss = 0.01054599\n",
      "Iteration 12, loss = 0.00970911\n",
      "Iteration 13, loss = 0.00985180\n",
      "Iteration 14, loss = 0.01010576\n",
      "Iteration 15, loss = 0.01025534\n",
      "Iteration 16, loss = 0.01016256\n",
      "Iteration 17, loss = 0.00857675\n",
      "Iteration 18, loss = 0.01013645\n",
      "Iteration 19, loss = 0.00914147\n",
      "Iteration 20, loss = 0.00892353\n",
      "Iteration 21, loss = 0.00948132\n",
      "Iteration 22, loss = 0.00908359\n",
      "Iteration 23, loss = 0.00862741\n",
      "Iteration 24, loss = 0.00851941\n",
      "Iteration 25, loss = 0.00838264\n",
      "Iteration 26, loss = 0.00831621\n",
      "Iteration 27, loss = 0.01003808\n",
      "Iteration 28, loss = 0.00945461\n",
      "Iteration 29, loss = 0.01013510\n",
      "Iteration 30, loss = 0.00850695\n",
      "Iteration 31, loss = 0.00880565\n",
      "Iteration 32, loss = 0.00869632\n",
      "Iteration 33, loss = 0.00875963\n",
      "Iteration 34, loss = 0.00827217\n",
      "Iteration 35, loss = 0.00841600\n",
      "Iteration 36, loss = 0.00832162\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "clf_mlp = MLPClassifier(hidden_layer_sizes=(128,64,32,), activation='relu' ,random_state=1, max_iter=300,verbose=True).fit(X_count_smote, y_count_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "39b7c509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TestSet(hatecheck_test_data_group_black people) LogisticRegression using CountVectorizer\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     hateful       0.76      0.95      0.84       357\n",
      " non-hateful       0.47      0.14      0.21       125\n",
      "\n",
      "    accuracy                           0.74       482\n",
      "   macro avg       0.62      0.54      0.53       482\n",
      "weighted avg       0.68      0.74      0.68       482\n",
      "\n",
      "Confusion Matrix\n",
      "[[338  19]\n",
      " [108  17]]\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "TestSet(hatecheck_test_data_group_disabled people) LogisticRegression using CountVectorizer\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     hateful       0.81      0.87      0.84       373\n",
      " non-hateful       0.41      0.31      0.35       111\n",
      "\n",
      "    accuracy                           0.74       484\n",
      "   macro avg       0.61      0.59      0.60       484\n",
      "weighted avg       0.72      0.74      0.73       484\n",
      "\n",
      "Confusion Matrix\n",
      "[[325  48]\n",
      " [ 77  34]]\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "TestSet(hatecheck_test_data_group_gay people) LogisticRegression using CountVectorizer\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     hateful       0.68      1.00      0.81       373\n",
      " non-hateful       0.86      0.03      0.06       178\n",
      "\n",
      "    accuracy                           0.69       551\n",
      "   macro avg       0.77      0.52      0.44       551\n",
      "weighted avg       0.74      0.69      0.57       551\n",
      "\n",
      "Confusion Matrix\n",
      "[[372   1]\n",
      " [172   6]]\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "TestSet(hatecheck_test_data_group_immigrants) LogisticRegression using CountVectorizer\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     hateful       0.82      0.70      0.75       357\n",
      " non-hateful       0.32      0.47      0.38       106\n",
      "\n",
      "    accuracy                           0.65       463\n",
      "   macro avg       0.57      0.58      0.57       463\n",
      "weighted avg       0.70      0.65      0.67       463\n",
      "\n",
      "Confusion Matrix\n",
      "[[249 108]\n",
      " [ 56  50]]\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "TestSet(hatecheck_test_data_group_Muslims) LogisticRegression using CountVectorizer\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     hateful       0.79      0.94      0.86       373\n",
      " non-hateful       0.47      0.18      0.26       111\n",
      "\n",
      "    accuracy                           0.76       484\n",
      "   macro avg       0.63      0.56      0.56       484\n",
      "weighted avg       0.72      0.76      0.72       484\n",
      "\n",
      "Confusion Matrix\n",
      "[[350  23]\n",
      " [ 91  20]]\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "TestSet(hatecheck_test_data_group_trans people) LogisticRegression using CountVectorizer\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     hateful       0.81      0.89      0.85       357\n",
      " non-hateful       0.43      0.28      0.34       106\n",
      "\n",
      "    accuracy                           0.75       463\n",
      "   macro avg       0.62      0.59      0.59       463\n",
      "weighted avg       0.72      0.75      0.73       463\n",
      "\n",
      "Confusion Matrix\n",
      "[[318  39]\n",
      " [ 76  30]]\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "TestSet(hatecheck_test_data_group_women) LogisticRegression using CountVectorizer\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     hateful       0.77      0.69      0.73       373\n",
      " non-hateful       0.35      0.45      0.39       136\n",
      "\n",
      "    accuracy                           0.63       509\n",
      "   macro avg       0.56      0.57      0.56       509\n",
      "weighted avg       0.66      0.63      0.64       509\n",
      "\n",
      "Confusion Matrix\n",
      "[[258 115]\n",
      " [ 75  61]]\n",
      "--------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for file_name in testset_file_names:\n",
    "    #read the test file\n",
    "    df_test = pd.read_csv(file_name)\n",
    "    #clean the text of test set\n",
    "    X_test, y_test = clean_data(df_test[\"text\"].tolist(),df_test[\"label\"].tolist())\n",
    "    #transform the matrix\n",
    "    X_test_Matrix = vect_count.transform(X_test)\n",
    "    #predict the matrix\n",
    "    y_pred = clf_mlp.predict(X_test_Matrix)\n",
    "    title = 'TestSet({}) LogisticRegression using CountVectorizer'.format(file_name[8:-4])\n",
    "    print(title)\n",
    "    cls_report = classification_report(y_test, y_pred)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    print(\"Classification Report\")\n",
    "    print(cls_report)\n",
    "    print(\"Confusion Matrix\")\n",
    "    print(conf_matrix)\n",
    "    print(\"-\"*110)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd932ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
